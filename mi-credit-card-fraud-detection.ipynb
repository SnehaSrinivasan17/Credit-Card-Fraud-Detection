{"metadata":{"accelerator":"GPU","colab":{"name":"Sahidul-Credit-Card-Fraud-Detection.ipynb","provenance":[]},"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing the libraries\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"colab_type":"code","id":"IBb6AuWDu6U5","outputId":"bf921bcd-fd07-451e-d7c4-4bcc75526937","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', 500)","metadata":{"colab":{},"colab_type":"code","id":"g43Ol5VWu6U_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory data analysis","metadata":{"colab_type":"text","id":"I-0zQPXfu6VF"}},{"cell_type":"markdown","source":"## Reading and understanding the data","metadata":{"colab_type":"text","id":"Bxf8Cw4Fu6VG"}},{"cell_type":"code","source":"# Reading the dataset\ndf = pd.read_csv('../input/creditcardfraud/creditcard.csv')\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"colab_type":"code","id":"nJT8RzWfu6VH","outputId":"4e6fdc84-2888-40ed-924a-c46f7a2e6f40","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"K5Z1nxMfu6VN","outputId":"91d012c6-d13b-48ea-ae83-92506a650b1e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":663},"colab_type":"code","id":"6YI-oSgUu6VS","outputId":"ac209d80-97db-4983-86a6-ae02dd680f18","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"colab_type":"code","id":"SxgZyGKvu6VX","outputId":"a9cb967a-3236-45e2-8bf5-cc8fac0ec387","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there is no missing values in any of the columns. Hence, there is no problem with null values in the entire dataset.","metadata":{"colab_type":"text","id":"MW8Myiwau6WV"}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking the distribution of the classes","metadata":{"colab_type":"text","id":"ya-zAvxdu6WX"}},{"cell_type":"code","source":"classes = df['Class'].value_counts()\nclasses","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"colab_type":"code","id":"VZVwJXggu6Wa","outputId":"33dc0b65-0a15-41b5-8532-6c02eae9a15b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal_share = round((classes[0]/df['Class'].count()*100),2)\nnormal_share","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"colab_type":"code","id":"BqVR11F2u6Wk","outputId":"357e600f-2050-4df6-88ff-be011c0fa92f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fraud_share = round((classes[1]/df['Class'].count()*100),2)\nfraud_share","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"colab_type":"code","id":"HJkpKiX_u6Wu","outputId":"099b98e0-5ffa-4f40-dfa0-aab20fdd077a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there is only 0.17% frauds. We will take care of the class imbalance later.","metadata":{"colab_type":"text","id":"5gT9ENElu6XF"}},{"cell_type":"code","source":"# Bar plot for the number of fraudulent vs non-fraudulent transcations\nsns.countplot(x='Class', data=df)\nplt.title('Number of fraudulent vs non-fraudulent transcations')\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"colab_type":"code","id":"-pOhCEWKu6XG","outputId":"b3c33f8a-a121-48b7-9a34-804ca94a21bb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bar plot for the percentage of fraudulent vs non-fraudulent transcations\nfraud_percentage = {'Class':['Non-Fraudulent', 'Fraudulent'], 'Percentage':[normal_share, fraud_share]} \ndf_fraud_percentage = pd.DataFrame(fraud_percentage) \nsns.barplot(x='Class',y='Percentage', data=df_fraud_percentage)\nplt.title('Percentage of fraudulent vs non-fraudulent transcations')\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"colab_type":"code","id":"jrNL8UKau6XV","outputId":"30fe88e9-9036-4b4c-e099-574bf45d2033","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outliers treatment","metadata":{"colab_type":"text","id":"J4i9QZjAu6Xe"}},{"cell_type":"markdown","source":"### Observe the distribution of classes with time","metadata":{"colab_type":"text","id":"vjP3ce_Au6Xn"}},{"cell_type":"code","source":"# Creating fraudulent dataframe\ndata_fraud = df[df['Class'] == 1]\n# Creating non fraudulent dataframe\ndata_non_fraud = df[df['Class'] == 0]","metadata":{"colab":{},"colab_type":"code","id":"7bFe7Q01u6Xp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution plot\nplt.figure(figsize=(8,5))\nax = sns.distplot(data_fraud['Time'],label='fraudulent',hist=False)\nax = sns.distplot(data_non_fraud['Time'],label='non fraudulent',hist=False)\nax.set(xlabel='Seconds elapsed between the transction and the first transction')\nplt.show()","metadata":{"colab":{},"colab_type":"code","id":"Vq76AVf_u6Xw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Analysis\nWe do not see any specific pattern for the fraudulent and non-fraudulent transctions with respect to Time.\nHence, we can drop the `Time` column.","metadata":{"colab_type":"text","id":"GAW4QoScu6X2"}},{"cell_type":"code","source":"# Dropping the Time column\ndf.drop('Time', axis=1, inplace=True)","metadata":{"colab":{},"colab_type":"code","id":"XnT3BqXHu6X4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observe the distribution of classes with amount","metadata":{"colab_type":"text","id":"Nm6gXB1Ou6YB"}},{"cell_type":"code","source":"# Distribution plot\nplt.figure(figsize=(8,5))\nax = sns.distplot(data_fraud['Amount'],label='fraudulent',hist=False)\nax = sns.distplot(data_non_fraud['Time'],label='non fraudulent',hist=False)\nax.set(xlabel='Transction Amount')\nplt.show()","metadata":{"colab":{},"colab_type":"code","id":"uxhBWt42u6YC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Analysis\nWe can see that the fraudulent transctions are mostly densed in the lower range of amount, whereas the non-fraudulent transctions are spreaded throughout low to high range of amount. ","metadata":{"colab_type":"text","id":"hPisBCVFu6YI"}},{"cell_type":"markdown","source":"## Train-Test Split","metadata":{"colab_type":"text","id":"dQ7CcJj5u6YK"}},{"cell_type":"code","source":"# Import library\nfrom sklearn.model_selection import train_test_split","metadata":{"colab":{},"colab_type":"code","id":"1t9AR81Mu6YL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Putting feature variables into X\nX = df.drop(['Class'], axis=1)","metadata":{"colab":{},"colab_type":"code","id":"YTvEou3eu6YS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Putting target variable to y\ny = df['Class']","metadata":{"colab":{},"colab_type":"code","id":"eBAoEhdKu6YY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data into train and test set 80:20\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=100)","metadata":{"colab":{},"colab_type":"code","id":"AT-JCXQCu6Yd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Scaling\nWe need to scale only the `Amount` column as all other columns are already scaled by the PCA transformation.","metadata":{"colab_type":"text","id":"ZjBOOoRRu6Yi"}},{"cell_type":"code","source":"# Standardization method\nfrom sklearn.preprocessing import StandardScaler","metadata":{"colab":{},"colab_type":"code","id":"ZzvfGrEau6Yj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate the Scaler\nscaler = StandardScaler()","metadata":{"colab":{},"colab_type":"code","id":"l6MgJu5Yu6Yq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the data into scaler and transform\nX_train['Amount'] = scaler.fit_transform(X_train[['Amount']])","metadata":{"colab":{},"colab_type":"code","id":"qF9gCgoLu6Yy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"colab_type":"code","id":"e3jOBWv5u6Y3","outputId":"74202183-a70d-43fe-efd9-ed599dba2cbf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Scaling the test set\nWe don't fit scaler on the test set. We only transform the test set.","metadata":{"colab_type":"text","id":"IPQlQ6CAu6Y8"}},{"cell_type":"code","source":"# Transform the test set\nX_test['Amount'] = scaler.transform(X_test[['Amount']])\nX_test.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"colab_type":"code","id":"7BNLTjaiu6Y9","outputId":"a99bb681-c9e5-4ae8-c196-d6b93bfb6b3a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking the Skewness","metadata":{"colab_type":"text","id":"wX6zSH6ju6ZC"}},{"cell_type":"code","source":"# Listing the columns\ncols = X_train.columns\ncols","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"colab_type":"code","id":"0lEY2C-gu6ZD","outputId":"301520f8-1710-4b60-a9a0-2541be68628e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the distribution of the variables (skewness) of all the columns\nk=0\nplt.figure(figsize=(17,28))\nfor col in cols :    \n    k=k+1\n    plt.subplot(6, 5,k)    \n    sns.distplot(X_train[col])\n    plt.title(col+' '+str(X_train[col].skew()))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"colab_type":"code","id":"IL_fIbyVu6ZM","outputId":"f9d0f885-217b-4790-e08e-2dfe933dffa6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that there are many variables, which are heavily skewed. We will mitigate the skewness only for those variables for bringing them into normal distribution.","metadata":{"colab_type":"text","id":"_2qcjquMu6ZU"}},{"cell_type":"markdown","source":"### Mitigate skweness with PowerTransformer","metadata":{"colab_type":"text","id":"PyT9p8Z_u6Zc"}},{"cell_type":"code","source":"# Importing PowerTransformer\nfrom sklearn.preprocessing import PowerTransformer\n# Instantiate the powertransformer\npt = PowerTransformer(method='yeo-johnson', standardize=True, copy=False)\n# Fit and transform the PT on training data\nX_train[cols] = pt.fit_transform(X_train)","metadata":{"colab":{},"colab_type":"code","id":"hLApGMuGu6Zd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform the test set\nX_test[cols] = pt.transform(X_test)","metadata":{"colab":{},"colab_type":"code","id":"Oq3JWqKku6Zr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the distribution of the variables (skewness) of all the columns\nk=0\nplt.figure(figsize=(17,28))\nfor col in cols :    \n    k=k+1\n    plt.subplot(6, 5,k)    \n    sns.distplot(X_train[col])\n    plt.title(col+' '+str(X_train[col].skew()))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"colab_type":"code","id":"Gn9LGnIuu6Zz","outputId":"ae8f2c87-5fc3-432e-ed8d-7a22ff50a6b8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can see that all the variables are normally distributed after the transformation.","metadata":{"colab_type":"text","id":"gG_PIa9cu6Z7"}},{"cell_type":"markdown","source":"### Logistic regression","metadata":{"colab_type":"text","id":"p1ZC72gpu6Z-"}},{"cell_type":"code","source":"# Importing scikit logistic regression module\nfrom sklearn.linear_model import LogisticRegression","metadata":{"colab":{},"colab_type":"code","id":"JkswPEwBu6Z_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Impoting metrics\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report","metadata":{"colab":{},"colab_type":"code","id":"1R-pakFmu6aE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Tuning hyperparameter  C\nC is the the inverse of regularization strength in Logistic Regression. Higher values of C correspond to less regularization.","metadata":{"colab_type":"text","id":"comrNu0yu6aJ"}},{"cell_type":"code","source":"# Importing libraries for cross validation\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV","metadata":{"colab":{},"colab_type":"code","id":"juSQ7kHxu6aK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating KFold object with 5 splits\nfolds = KFold(n_splits=5, shuffle=True, random_state=4)\n\n# Specify params\nparams = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n\n# Specifing score as recall as we are more focused on acheiving the higher sensitivity than the accuracy\nmodel_cv = GridSearchCV(estimator = LogisticRegression(),\n                        param_grid = params, \n                        scoring= 'roc_auc', \n                        cv = folds, \n                        verbose = 1,\n                        return_train_score=True) \n\n# Fit the model\nmodel_cv.fit(X_train, y_train)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":306},"colab_type":"code","id":"yTvEVU6Uu6aQ","outputId":"f6acd2b0-b324-47a4-b31f-f5a1c2d279aa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results of grid search CV\ncv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"colab_type":"code","id":"1srhQzaPu6aZ","outputId":"455fd28a-74c2-4eee-8673-4d73302304d6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot of C versus train and validation scores\n\nplt.figure(figsize=(8, 6))\nplt.plot(cv_results['param_C'], cv_results['mean_test_score'])\nplt.plot(cv_results['param_C'], cv_results['mean_train_score'])\nplt.xlabel('C')\nplt.ylabel('roc_auc')\nplt.legend(['test result', 'train result'], loc='upper left')\nplt.xscale('log')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"colab_type":"code","id":"eQHPJncVu6af","outputId":"2ae64ea3-5903-413e-8b28-aa45967d19a9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best score with best C\nbest_score = model_cv.best_score_\nbest_C = model_cv.best_params_['C']\n\nprint(\" The highest test roc_auc is {0} at C = {1}\".format(best_score, best_C))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"R2WOKQIuu6ap","outputId":"1217dd08-dddc-473e-b5d3-5cfc1c101e76","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate the model with best C\nlogistic_imb = LogisticRegression(C=0.01)","metadata":{"colab":{},"colab_type":"code","id":"x4iUliVvu6a0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model on the train set\nlogistic_imb_model = logistic_imb.fit(X_train, y_train)","metadata":{"colab":{},"colab_type":"code","id":"fEPWrysIu6a7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Prediction on the train set","metadata":{"colab_type":"text","id":"NGre5jWku6ba"}},{"cell_type":"code","source":"# Predictions on the train set\ny_train_pred = logistic_imb_model.predict(X_train)","metadata":{"colab":{},"colab_type":"code","id":"mmHmFtRdu6bc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix\nconfusion = metrics.confusion_matrix(y_train, y_train_pred)\nprint(confusion)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","id":"UH2_OXo2u6bh","outputId":"45de9b1e-2190-4c12-c1f4-a49fa622cb86","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","metadata":{"colab":{},"colab_type":"code","id":"ZXhDRhYDu6bm","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy\nprint(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train_pred))\n\n# Sensitivity\nprint(\"Sensitivity:-\",TP / float(TP+FN))\n\n# Specificity\nprint(\"Specificity:-\", TN / float(TN+FP))\n\n# F1 score\nprint(\"F1-Score:-\", f1_score(y_train, y_train_pred))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","id":"cb5nfmExu6bu","outputId":"06d2f11a-8471-4f19-89c5-b76f35e9e434","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classification_report\nprint(classification_report(y_train, y_train_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### ROC on the train set","metadata":{"colab_type":"text","id":"ZQhL6zC_u6by"}},{"cell_type":"code","source":"# ROC Curve function\n\ndef draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","metadata":{"colab":{},"colab_type":"code","id":"CqQli61Gu6bz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicted probability\ny_train_pred_proba = logistic_imb_model.predict_proba(X_train)[:,1]","metadata":{"colab":{},"colab_type":"code","id":"u3lsDBWDu6b7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the ROC curve\ndraw_roc(y_train, y_train_pred_proba)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"colab_type":"code","id":"dTt47Imiu6cE","outputId":"21849b41-3798-498f-d532-4ef288ca60ce","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We acheived very good ROC 0.99 on the train set.","metadata":{"colab_type":"text","id":"Iwomdpwcu6cJ"}},{"cell_type":"markdown","source":"#### Prediction on the test set","metadata":{"colab_type":"text","id":"z61H8NcIu6cL"}},{"cell_type":"code","source":"# Prediction on the test set\ny_test_pred = logistic_imb_model.predict(X_test)","metadata":{"colab":{},"colab_type":"code","id":"zCzUiIIHu6cM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix\nconfusion = metrics.confusion_matrix(y_test, y_test_pred)\nprint(confusion)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","id":"rta2aGEku6cT","outputId":"5d0c5abb-2ad7-4772-d76f-ce2f447d3b2c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","metadata":{"colab":{},"colab_type":"code","id":"ILfPTUnVu6cc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy\nprint(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n\n# Sensitivity\nprint(\"Sensitivity:-\",TP / float(TP+FN))\n\n# Specificity\nprint(\"Specificity:-\", TN / float(TN+FP))\n\n# F1 score\nprint(\"F1-Score:-\", f1_score(y_test, y_test_pred))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","id":"lyVM_U_Eu6ch","outputId":"50e5280a-e3ba-40f2-a594-93c6331aa818","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classification_report\nprint(classification_report(y_test, y_test_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### ROC on the test set","metadata":{"colab_type":"text","id":"eHufzVLeu6cm"}},{"cell_type":"code","source":"# Predicted probability\ny_test_pred_proba = logistic_imb_model.predict_proba(X_test)[:,1]","metadata":{"colab":{},"colab_type":"code","id":"65bwEos7u6cm","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the ROC curve\ndraw_roc(y_test, y_test_pred_proba)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"colab_type":"code","id":"6NGDwjyau6cq","outputId":"b3f67c30-440a-4fb2-af38-dfe02c78651d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that we have very good ROC on the test set 0.97, which is almost close to 1.","metadata":{"colab_type":"text","id":"BNVtUmj2u6cv"}},{"cell_type":"markdown","source":"***Model summary***\n\n- Train set\n    - Accuracy = 0.99\n    - Sensitivity = 0.70\n    - Specificity = 0.99\n    - F1-Score = 0.76\n    - ROC = 0.99\n- Test set\n    - Accuracy = 0.99\n    - Sensitivity = 0.77\n    - Specificity = 0.99\n    - F1-Score = 0.65\n    - ROC = 0.97\n\nOverall, the model is performing well in the test set, what it had learnt from the train set.","metadata":{"colab_type":"text","id":"npP3Sjspu6cw"}},{"cell_type":"markdown","source":"### XGBoost","metadata":{"colab_type":"text","id":"fMQ3LVL2u6cx"}},{"cell_type":"code","source":"# Importing XGBoost\nfrom xgboost import XGBClassifier","metadata":{"colab":{},"colab_type":"code","id":"rVaOVLGTu6cx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Tuning the hyperparameters","metadata":{"colab_type":"text","id":"sBzFkTiwu6c2"}},{"cell_type":"code","source":"# hyperparameter tuning with XGBoost\n\n# creating a KFold object \nfolds = 3\n\n# specify range of hyperparameters\nparam_grid = {'learning_rate': [0.2, 0.6], \n             'subsample': [0.3, 0.6, 0.9]}          \n\n\n# specify model\nxgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n\n# set up GridSearchCV()\nmodel_cv = GridSearchCV(estimator = xgb_model, \n                        param_grid = param_grid, \n                        scoring= 'roc_auc', \n                        cv = folds, \n                        verbose = 1,\n                        return_train_score=True)      \n\n# fit the model\nmodel_cv.fit(X_train, y_train)       ","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"colab_type":"code","id":"eesdL5dLu6c3","outputId":"639eabce-c2ae-40ff-b0ca-77ad9e31b5b4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv results\ncv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":561},"colab_type":"code","id":"hbjPR_wgu6c6","outputId":"dd8e7110-7b81-4a89-d407-478679bc1baa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # plotting\nplt.figure(figsize=(16,6))\n\nparam_grid = {'learning_rate': [0.2, 0.6], \n             'subsample': [0.3, 0.6, 0.9]} \n\n\nfor n, subsample in enumerate(param_grid['subsample']):\n    \n\n    # subplot 1/n\n    plt.subplot(1,len(param_grid['subsample']), n+1)\n    df = cv_results[cv_results['param_subsample']==subsample]\n\n    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n    plt.xlabel('learning_rate')\n    plt.ylabel('AUC')\n    plt.title(\"subsample={0}\".format(subsample))\n    plt.ylim([0.60, 1])\n    plt.legend(['test score', 'train score'], loc='upper left')\n    plt.xscale('log')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"colab_type":"code","id":"tfUn8kJ6u6c9","outputId":"6ffbe177-d0b9-4443-eabd-fd935b69024a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Model with optimal hyperparameters\nWe see that the train score almost touches to 1. Among the hyperparameters, we can choose the best parameters as learning_rate : 0.2 and subsample: 0.3","metadata":{"colab_type":"text","id":"bdIyusKeu6dA"}},{"cell_type":"code","source":"model_cv.best_params_","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"nIHTe9iGu6dA","outputId":"bd239286-3bad-426f-e676-1ee1d28fa6e3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# chosen hyperparameters\n# 'objective':'binary:logistic' outputs probability rather than label, which we need for calculating auc\nparams = {'learning_rate': 0.2,\n          'max_depth': 2, \n          'n_estimators':200,\n          'subsample':0.9,\n         'objective':'binary:logistic'}\n\n# fit model on training data\nxgb_imb_model = XGBClassifier(params = params)\nxgb_imb_model.fit(X_train, y_train)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":170},"colab_type":"code","id":"4ZWn61VWu6dD","outputId":"9e7e2d9d-4d32-4193-8608-09c1e243f873","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Prediction on the train set","metadata":{"colab_type":"text","id":"UWm75lMJu6dF"}},{"cell_type":"code","source":"# Predictions on the train set\ny_train_pred = xgb_imb_model.predict(X_train)","metadata":{"colab":{},"colab_type":"code","id":"8ftImmA-u6dF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix\nconfusion = metrics.confusion_matrix(y_train, y_train_pred)\nprint(confusion)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","id":"hIbppSpyu6dJ","outputId":"8f123cca-192a-40ff-93a7-4bc7edca56fc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","metadata":{"colab":{},"colab_type":"code","id":"bVOJFGv5u6dN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy\nprint(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train_pred))\n\n# Sensitivity\nprint(\"Sensitivity:-\",TP / float(TP+FN))\n\n# Specificity\nprint(\"Specificity:-\", TN / float(TN+FP))\n\n# F1 score\nprint(\"F1-Score:-\", f1_score(y_train, y_train_pred))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","id":"XWCn7cBTu6dT","outputId":"981656b5-cc82-46a8-a158-8cf33530a520","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classification_report\nprint(classification_report(y_train, y_train_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicted probability\ny_train_pred_proba_imb_xgb = xgb_imb_model.predict_proba(X_train)[:,1]","metadata":{"colab":{},"colab_type":"code","id":"T-xWIPUQu6dW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roc_auc\nauc = metrics.roc_auc_score(y_train, y_train_pred_proba_imb_xgb)\nauc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"1WrajBKSu6dZ","outputId":"5bc78aab-9f29-4aef-d82c-1b14b2d526a1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the ROC curve\ndraw_roc(y_train, y_train_pred_proba_imb_xgb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Prediction on the test set","metadata":{"colab_type":"text","id":"421AFLmmu6dd"}},{"cell_type":"code","source":"# Predictions on the test set\ny_test_pred = xgb_imb_model.predict(X_test)","metadata":{"colab":{},"colab_type":"code","id":"97fAvuBSu6de","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix\nconfusion = metrics.confusion_matrix(y_test, y_test_pred)\nprint(confusion)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","id":"UNIsCGbfu6dh","outputId":"1880b76f-3ab5-45ac-dfdc-79c1c6f1ad76","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","metadata":{"colab":{},"colab_type":"code","id":"I3a8YNlJu6dl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy\nprint(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n\n# Sensitivity\nprint(\"Sensitivity:-\",TP / float(TP+FN))\n\n# Specificity\nprint(\"Specificity:-\", TN / float(TN+FP))\n\n# F1 score\nprint(\"F1-Score:-\", f1_score(y_test, y_test_pred))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","id":"iCgfikWxu6dp","outputId":"15e2ce19-8e86-4b19-aabf-12afed252d18","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classification_report\nprint(classification_report(y_test, y_test_pred))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicted probability\ny_test_pred_proba = xgb_imb_model.predict_proba(X_test)[:,1]","metadata":{"colab":{},"colab_type":"code","id":"1iPpaLtDu6ds","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roc_auc\nauc = metrics.roc_auc_score(y_test, y_test_pred_proba)\nauc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"QwSGPvnqu6dv","outputId":"fd8ec92c-23a1-4584-893d-1a5f210f116d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the ROC curve\ndraw_roc(y_test, y_test_pred_proba)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Model summary***\n\n- Train set\n    - Accuracy = 0.99\n    - Sensitivity = 0.85\n    - Specificity = 0.99\n    - ROC-AUC = 0.99\n    - F1-Score = 0.90\n- Test set\n    - Accuracy = 0.99\n    - Sensitivity = 0.75\n    - Specificity = 0.99\n    - ROC-AUC = 0.98\n    - F-Score = 0.79\n\nOverall, the model is performing well in the test set, what it had learnt from the train set.","metadata":{"colab_type":"text","id":"Xm23el46u6dx"}},{"cell_type":"markdown","source":"### Decision Tree","metadata":{"colab_type":"text","id":"aj4qybydu6dy"}},{"cell_type":"code","source":"# Importing decision tree classifier\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"colab":{},"colab_type":"code","id":"pacANTsyu6dy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the parameter grid \nparam_grid = {\n    'max_depth': range(5, 15, 5),\n    'min_samples_leaf': range(50, 150, 50),\n    'min_samples_split': range(50, 150, 50),\n}\n\n\n# Instantiate the grid search model\ndtree = DecisionTreeClassifier()\n\ngrid_search = GridSearchCV(estimator = dtree, \n                           param_grid = param_grid, \n                           scoring= 'roc_auc',\n                           cv = 3, \n                           verbose = 1)\n\n# Fit the grid search to the data\ngrid_search.fit(X_train,y_train)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"colab_type":"code","id":"Xf10KIeSu6d2","outputId":"d9279a88-ddee-4e01-da59-d75f4817f835","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv results\ncv_results = pd.DataFrame(grid_search.cv_results_)\ncv_results","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":589},"colab_type":"code","id":"keumhyPCu6d8","outputId":"bb51de4f-83c6-4313-d3e8-16ae174e6023","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing the optimal sensitivity score and hyperparameters\nprint(\"Best roc_auc:-\", grid_search.best_score_)\nprint(grid_search.best_estimator_)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"colab_type":"code","id":"3O0n7PR7u6eA","outputId":"7be39ec4-a271-46e0-bd68-c1ef37d0e5e0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model with optimal hyperparameters\ndt_imb_model = DecisionTreeClassifier(criterion = \"gini\", \n                                  random_state = 100,\n                                  max_depth=5, \n                                  min_samples_leaf=100,\n                                  min_samples_split=100)\n\ndt_imb_model.fit(X_train, y_train)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119},"colab_type":"code","id":"XHH22W7Au6eE","outputId":"aea16672-121b-41f7-f37f-df8a35f74339","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Prediction on the train set","metadata":{"colab_type":"text","id":"teEhvb4pu6eH"}},{"cell_type":"code","source":"# Predictions on the train set\ny_train_pred = dt_imb_model.predict(X_train)","metadata":{"colab":{},"colab_type":"code","id":"9AWP9dsuu6eH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix\nconfusion = metrics.confusion_matrix(y_train, y_train)\nprint(confusion)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","id":"mA42jj0uu6eJ","outputId":"67906e8b-e8f4-4991-ed27-6ce3d21f1919","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","metadata":{"colab":{},"colab_type":"code","id":"5hiYzaGIu6eM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy\nprint(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train_pred))\n\n# Sensitivity\nprint(\"Sensitivity:-\",TP / float(TP+FN))\n\n# Specificity\nprint(\"Specificity:-\", TN / float(TN+FP))\n\n# F1 score\nprint(\"F1-Score:-\", f1_score(y_train, y_train_pred))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","id":"BNfGD46ku6eO","outputId":"2cbe7cbc-17d6-4d6c-85ab-7b356a259252","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classification_report\nprint(classification_report(y_train, y_train_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicted probability\ny_train_pred_proba = dt_imb_model.predict_proba(X_train)[:,1]","metadata":{"colab":{},"colab_type":"code","id":"j4AzB2jYu6eQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roc_auc\nauc = metrics.roc_auc_score(y_train, y_train_pred_proba)\nauc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"WV2xY0dhu6eT","outputId":"2c642425-3737-4607-c708-dd11f493dc2f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the ROC curve\ndraw_roc(y_train, y_train_pred_proba)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Prediction on the test set","metadata":{"colab_type":"text","id":"OXblPUcyu6eV"}},{"cell_type":"code","source":"# Predictions on the test set\ny_test_pred = dt_imb_model.predict(X_test)","metadata":{"colab":{},"colab_type":"code","id":"Drgvh5S-u6eW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix\nconfusion = metrics.confusion_matrix(y_test, y_test_pred)\nprint(confusion)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","id":"8lmZszZdu6eY","outputId":"1ebc8652-7792-4abf-8e02-1fca7b36222e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","metadata":{"colab":{},"colab_type":"code","id":"2xnFAIS4u6eb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy\nprint(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n\n# Sensitivity\nprint(\"Sensitivity:-\",TP / float(TP+FN))\n\n# Specificity\nprint(\"Specificity:-\", TN / float(TN+FP))\n\n# F1 score\nprint(\"F1-Score:-\", f1_score(y_train, y_train_pred))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","id":"EMb4H8n2u6ed","outputId":"88ed89d6-6760-4f33-d47e-d8584683fe57","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classification_report\nprint(classification_report(y_test, y_test_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicted probability\ny_test_pred_proba = dt_imb_model.predict_proba(X_test)[:,1]","metadata":{"colab":{},"colab_type":"code","id":"id8aFm_Mu6ef","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roc_auc\nauc = metrics.roc_auc_score(y_test, y_test_pred_proba)\nauc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"af7a5a4mu6ek","outputId":"6c7cd7e3-92c6-442c-8b81-01e1aed79941","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the ROC curve\ndraw_roc(y_test, y_test_pred_proba)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Model summary***\n\n- Train set\n    - Accuracy = 0.99\n    - Sensitivity = 1.0\n    - Specificity = 1.0\n    - F1-Score = 0.75\n    - ROC-AUC = 0.95\n- Test set\n    - Accuracy = 0.99\n    - Sensitivity = 0.58\n    - Specificity = 0.99\n    - F-1 Score = 0.75\n    - ROC-AUC = 0.92","metadata":{}}]}